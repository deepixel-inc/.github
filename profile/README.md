# Deepixel : Real-time Visual Intelligence Algorithms


[![Deepixel](https://img.shields.io/badge/Deepixel-Visit%20Website-blue?style=flat-square)](https://www.deepixel.xyz)
[![StyleAR](https://img.shields.io/badge/StyleAR-Visit%20Website-pink?style=flat-square)](https://www.stylear.ai)
[![Get License](https://img.shields.io/badge/Get%20License-Contact%20Us-yellow)](#license)

## About Deepixel

**Deepixel** is a visual-intelligence deep-tech startup based in **Seoul, South Korea**, specializing in **real-time human understanding algorithms** using a **single RGB camera**.

We design and optimize proprietary **computer vision** and **machine learning** pipelines that perform robust **3D pose estimation**, **high-precision landmark detection**, and **temporal tracking** across **mobile and web environments**.

Deepixel operates a **fully in-house vision R&D stack**, covering **raw data acquisition**, **custom annotation pipelines**, **deep learning model design and training**, and **platform-specific optimization**. This end-to-end ownership allows us to tightly couple data, models, and inference pipelines, ensuring **algorithmic efficiency, stability, and accuracy under real-world constraints**, and enabling solutions that are precisely tailored to the needs of each vision problem and deployment platform.

---

## Core Algorithmic Focus

Deepixel‚Äôs vision stack is built around the following principles:

* **Single-Camera Geometry**  
  Inferring 3D structure and pose from monocular RGB input

* **Real-Time Inference**  
  Low-latency pipelines optimized for mobile CPUs, GPUs, and NPUs

* **Robustness in the Wild**  
  Designed to handle occlusion, motion blur, illumination changes, and extreme poses

* **Lightweight Models**  
  Architectures optimized for on-device inference without cloud dependency

---

## Core Vision Capabilities

### üë§ Face & Ear Tracking
- Dense facial landmark detection
- 3D head pose estimation (rotation & translation)
- Ear landmark inference under partial occlusion
- Stable temporal tracking for AR alignment

### ‚úã Hand & Finger Tracking
- 21-keypoint hand skeleton estimation
- Per-joint confidence and visibility modeling
- Optimized for fast motion and self-occlusion
- Suitable for gesture recognition and fine-grained interaction

### ‚åö Wrist Tracking
- Wrist-specific landmark topology
- 3D wrist orientation estimation
- Stable tracking under rotation and partial visibility
- Designed for watch and bracelet alignment

### üßç Full-Body Pose Estimation
- Multi-joint human pose understanding
- Robust keypoint localization under self-occlusion
- Temporal smoothing for stable motion tracking
- Applicable to fitness, fashion, and HCI

### üëü Foot Tracking
- Foot landmark detection and orientation estimation
- Supports size alignment and ground contact reasoning
- Designed for real-time footwear AR and biomechanics use cases

---

## Algorithmic Characteristics

* Monocular 3D reconstruction
* Learned geometric priors
* Temporal filtering & motion consistency
* Landmark-centric representations
* ROI-based inference pipelines
* Cross-platform deterministic behavior

These characteristics allow our models to remain **accurate, fast, and stable** even on constrained devices.

---

## Repositories

| Repository | Description |
|-----------|-------------|
| **face-tracking**  | High-performance facial landmark & pose estimation |
| **wrist-tracking** | Wrist-specific landmark & pose inference |

üëâ See individual repositories for implementation details and benchmarks.

---

## Recognition

Deepixel‚Äôs technology has been recognized internationally:

* **CES Innovation Awards Honoree**
* **KES Innovation Award**
* **Intelligence Start-up Award**
* Backed by **NAVER D2 Startup Factory (D2SF)**

These recognitions reflect our strength in **core vision algorithms**, not just applications.

---

## Use Cases

Our algorithms are designed to support:

* Augmented Reality alignment
* Spatial computing interfaces
* Human-computer interaction (HCI)
* Virtual try-on systems
* Motion analysis & tracking
* On-device AI vision systems

---

## Collaboration

We welcome collaboration with:

* Computer vision / Deep learning researchers
* AR / XR engineers
* Data scientist
* Hardware & camera platform teams
* Developers building real-time vision systems

üì¨ **deepixel@deepixel.xyz**  
üåê **https://www.deepixel.xyz**  
üìç Seoul, Republic of Korea


